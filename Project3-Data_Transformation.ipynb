{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"proj3.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Data Transformation\n",
    "\n",
    "## Due Date: Friday 10/28, 11:59 PM\n",
    "\n",
    "## Assignment Details\n",
    "\n",
    "In this project, we'll be working with one month of data from sensors in buildings at UC Berkeley. This is a very typical real-world dataset---i.e. it's kind of a mess. The full dataset contains a giant `data` table of sensor readings that is many billions of readings over the course of a decade; we will look at a single month of that data. It also contains a variety of other tables that contextualize the readings.\n",
    "\n",
    "The schema for the database is shown below. Sometimes people think that if the data is a nice schema, then it's ready to go! We'll see about that.\n",
    "\n",
    "**Note:** Each line represents a relationship between the two fields. The side of the line diverging to three lines / arrows suggests the \"many\" side of the relationship, while the side of the line converging to one arrow suggests the \"one\" side of the relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/schema.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistics & Scoring Breakdown\n",
    "\n",
    "For Data 101 students, this project is worth 15% of your grade. For Info 258 students, this project is worth 12% of your grade.\n",
    "\n",
    "Each coding question has **both public tests and hidden tests**. Roughly 50% of your coding grade will be made up of your score on the public tests released to you, while the remaining 50% will be made up of unreleased hidden tests. Free-response questions will be manually graded.\n",
    "\n",
    "This is an **individual project**. However, you’re welcome to collaborate with any other student in the class as long as it’s within the academic honesty guidelines.\n",
    "\n",
    "Question | Points\n",
    "--- | ---\n",
    "1a\t| 1\n",
    "1b  | 1\n",
    "1c\t| 1\n",
    "1d\t| 2\n",
    "2a\t| 3\n",
    "2b\t| 1\n",
    "3a\t| 0\n",
    "3b\t| 1\n",
    "3c\t| 1\n",
    "3d  | 0\n",
    "3e  | 2\n",
    "4a\t| 2\n",
    "4b\t| 2\n",
    "4c\t| 3\n",
    "**Total** | 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to set up imports\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext sql\n",
    "%sql postgresql://jovyan@127.0.0.1:5432/template1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Up the Database\n",
    "To load the database, run the following cell.\n",
    "\n",
    "**IMPORTANT NOTE:** In contrary to previous projects, the database does not reload automatically upon running the following loading cell. If you would like to reload the database (e.g. if your database is modified in undesirable ways), **first restart the kernel**, and then run `!psql -h localhost -c 'DROP DATABASE IF EXISTS ucb_buildings'` in another cell **before** running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database was previously loaded.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "call = subprocess.run([\"psql\", \"-h\", \"localhost\", \\\n",
    "                       \"-tAc\", \"SELECT 1 FROM pg_database WHERE datname='ucb_buildings'\", \"template1\"], \\\n",
    "                      stdout=subprocess.PIPE, text=True)\n",
    "\n",
    "if call.stdout != \"1\\n\":\n",
    "    print(\"Loading database...\")\n",
    "    os.system(\"gunzip -c data/proj3.sql.gz | psql -h localhost -d template1 -f -\")\n",
    "else:\n",
    "    print(\"Database was previously loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the following cell to connect to the `ucb_buildings` database. There should be no errors after running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql postgresql://jovyan@127.0.0.1:5432/ucb_buildings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell for grading purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Question 1: Unboxing the Data\n",
    "\n",
    "### Question 1a\n",
    "\n",
    "Note that the `data` table, in the full database, is billions of rows. What do you notice about the design of the database schema that helps support the large amount of data?\n",
    "\n",
    "**Hint:** There is no need to examine any data here. What is a technique learned in [lecture 15](https://docs.google.com/presentation/d/1GogwyAylHrJoxer_apIkgnWDqC9LxTQ8/edit)? Define that technique.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a\n",
    "manual: true\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schema is based on an entity relationship which avoids redundancy and uses primary keys. The relations are also normalized, split into multiple relations, which minimizes redundancy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "### Question 1b\n",
    "\n",
    "The diagram claims that `buildings_site_mapping` has a many-to-many relationship with `real_estate_metadata`. Let's validate that. \n",
    "\n",
    "Below is an example of `json_agg` being used with a table; you will need to do this in the next two parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   postgresql://jovyan@127.0.0.1:5432/template1\n",
      " * postgresql://jovyan@127.0.0.1:5432/ucb_buildings\n",
      "5 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>site</th>\n",
       "        <th>json_agg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Sutardja Dai Hall</td>\n",
       "        <td>[{&#x27;site&#x27;: &#x27;Sutardja Dai Hall&#x27;, &#x27;building&#x27;: &#x27;SUTARDJA DAI&#x27;}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Le Conte Hall</td>\n",
       "        <td>[{&#x27;site&#x27;: &#x27;Le Conte Hall&#x27;, &#x27;building&#x27;: &#x27;LE CONTE&#x27;}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Hildebrand Hall</td>\n",
       "        <td>[{&#x27;site&#x27;: &#x27;Hildebrand Hall&#x27;, &#x27;building&#x27;: &#x27;HILDEBRA ND&#x27;}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Stephens Hall</td>\n",
       "        <td>[{&#x27;site&#x27;: &#x27;Stephens Hall&#x27;, &#x27;building&#x27;: &#x27;STEPHENS&#x27;}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2000 Carleton Street</td>\n",
       "        <td>[{&#x27;site&#x27;: &#x27;2000 Carleton Street&#x27;, &#x27;building&#x27;: &#x27;CARLETO2 000&#x27;}]</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('Sutardja Dai Hall', [{'site': 'Sutardja Dai Hall', 'building': 'SUTARDJA DAI'}]),\n",
       " ('Le Conte Hall', [{'site': 'Le Conte Hall', 'building': 'LE CONTE'}]),\n",
       " ('Hildebrand Hall', [{'site': 'Hildebrand Hall', 'building': 'HILDEBRA ND'}]),\n",
       " ('Stephens Hall', [{'site': 'Stephens Hall', 'building': 'STEPHENS'}]),\n",
       " ('2000 Carleton Street', [{'site': '2000 Carleton Street', 'building': 'CARLETO2 000'}])]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT b.site, json_agg(b) from buildings_site_mapping b GROUP BY b.site LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the **distinct** values of `buildings_site_mapping.building` that match multiple tuples in `real_estate_metadata.building_name`, and for each such value of `buildings_site_mapping.building` return the matches as JSON via `json_agg(real_estate_metadata)`. Your output should contain the building and the `json_agg` in that order. Order your final result by building.\n",
    "\n",
    "**Hint:** You should use a CTE to find the distinct buildings of `buildings_site_mapping` before applying necessary table joins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   postgresql://jovyan@127.0.0.1:5432/template1\n",
      " * postgresql://jovyan@127.0.0.1:5432/ucb_buildings\n",
      "5 rows affected.\n",
      "Returning data to local variable result_1b\n"
     ]
    }
   ],
   "source": [
    "%%sql result_1b <<\n",
    "WITH dist_buildings AS (\n",
    "    SELECT DISTINCT building\n",
    "    FROM buildings_site_mapping\n",
    ")\n",
    "SELECT b.building, json_agg(r)\n",
    "FROM dist_buildings AS b\n",
    "JOIN real_estate_metadata AS r\n",
    "ON b.building = r.building_name\n",
    "GROUP BY b.building HAVING COUNT(*) > 1\n",
    "ORDER BY b.building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell\n",
    "result_1b.DataFrame().to_csv('results/result_1b.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1b</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q1b results: All test cases passed!"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1c\n",
    "\n",
    "Now find examples of many matches in the opposite direction. For each distinct `real_estate_metadata.building_name` value, find the ones that have multiple matches in `buildings_site_mapping.building`, and for each return a `json_agg` of the multiple values for `buildings_site_mapping`. Your output should contain the building name and the `json_agg` in that order. Order your final result by building name.\n",
    "\n",
    "**Hint:** You should use a CTE to find the distinct building names of `real_estate_metadata` before applying necessary table joins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   postgresql://jovyan@127.0.0.1:5432/template1\n",
      " * postgresql://jovyan@127.0.0.1:5432/ucb_buildings\n",
      "4 rows affected.\n",
      "Returning data to local variable result_1c\n"
     ]
    }
   ],
   "source": [
    "%%sql result_1c <<\n",
    "WITH dist_buildings AS (\n",
    "    SELECT DISTINCT building_name\n",
    "    FROM real_estate_metadata\n",
    ")\n",
    "SELECT d.building_name, json_agg(b)\n",
    "FROM dist_buildings AS d\n",
    "JOIN buildings_site_mapping AS b\n",
    "ON b.building = d.building_name\n",
    "GROUP BY d.building_name HAVING COUNT(*) > 1\n",
    "ORDER BY d.building_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell\n",
    "result_1c.DataFrame().to_csv('results/result_1c.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1c</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q1c results: All test cases passed!"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 1d\n",
    "\n",
    "Do you see any issues with the schema given? In particular, please address the two questions below:\n",
    "- Can you uniquely determine the building given the sensor data? Why? (**Hint:** given a row in the `data` table, can you determine a **uniquely** associated row in `real_estate_metadata` table? Your answer should draw insights from 1b.)\n",
    "- Could `buildings_site_mapping.building` be a valid foreign key pointing to `real_estate_metadata.building_name`? (**Hint:** think about the definition / constraints of a foreign key.)\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1d\n",
    "manual: true\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in 1b, buildings_site_mapping.building matches multiple tuples in real_estate_metadata.building_name and id in is only unique to the sensor value for that unique time but not the buildings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## Question 2: Looking for Outliers in the Readings\n",
    "Physical sensors like the ones generating this data are notorious for producing crazy outliers on occasion. In this section we'll do a little data cleaning of the outliers.\n",
    "\n",
    "All the readings from all different kinds of sensors are mixed together in the `data` table. This hodgepodge of mixed readings is going to require us to do some extra work to look for outliers. Let's get started.\n",
    "\n",
    "### Question 2a: Outlier Detection\n",
    "\n",
    "Let's find the outlying values *for each sensor id*. We'll call something an outlier if it is **3 Hampel X84 intervals** away from the median. If \n",
    "\n",
    "Specifically, create a view `labeled_data` that contains all of the columns in `data` and adds three additional columns at the far right:\n",
    "  - `median` containing the median using `percentile_disc`\n",
    "  - `mad` containing the Median Absolute Deviation (MAD),\n",
    "  - `outlier` that contains `true` for the outlier readings and `false` for the rest. **Also,** for data points where the mad is 0, set this to `false`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   postgresql://jovyan@127.0.0.1:5432/template1\n",
      " * postgresql://jovyan@127.0.0.1:5432/ucb_buildings\n",
      "Done.\n",
      "100 rows affected.\n",
      "Returning data to local variable result_2a\n"
     ]
    }
   ],
   "source": [
    "%%sql result_2a <<\n",
    "CREATE OR REPLACE VIEW labeled_data AS\n",
    "WITH medians AS (\n",
    "    SELECT id, percentile_disc(0.5) WITHIN GROUP (ORDER BY value) AS median\n",
    "    FROM data\n",
    "    GROUP BY id\n",
    ")\n",
    ", absdev AS (\n",
    "    SELECT data.id, data.value, median, abs(value - m.median) AS d\n",
    "    FROM data\n",
    "    JOIN medians AS m\n",
    "    ON data.id = m.id\n",
    ")\n",
    ", mads AS (\n",
    "    SELECT id, median, percentile_disc(0.5) WITHIN GROUP (ORDER BY d) AS mad\n",
    "    FROM absdev\n",
    "    GROUP BY id, median\n",
    ")\n",
    ", comb AS (\n",
    "    SELECT time, d.id, value, median, mad\n",
    "    FROM data AS d\n",
    "    RIGHT JOIN mads AS m\n",
    "    ON d.id = m.id\n",
    ")\n",
    "SELECT time, id, value, median, mad, \n",
    "    CASE \n",
    "        WHEN mad = 0 THEN False \n",
    "        WHEN value < (median - 3 * mad * 1.4826) THEN True \n",
    "        WHEN value > (3 * mad * 1.4826 + median) THEN True \n",
    "        ELSE False END\n",
    "        AS outlier\n",
    "FROM comb\n",
    ";\n",
    "SELECT * FROM labeled_data WHERE outlier ORDER BY id, time LIMIT 100;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell\n",
    "result_2a.DataFrame().to_csv('results/result_2a.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2a</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q2a results: All test cases passed!"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2b: Outlier Handling (Winsorization)\n",
    "\n",
    "In this step we'll define a view `cleaned_data` over all the columns of `labeled_data` and one additional column on the far right called `clean_value`. This column will contain a copy of `data.value` if that value is not an outlier. For outliers, it should contain the value Winsorized to the nearest outlier boundary value (3 Hampel X84 intervals from the median). If the MAD is 0, then the cleaned value should be the same as the original value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   postgresql://jovyan@127.0.0.1:5432/template1\n",
      " * postgresql://jovyan@127.0.0.1:5432/ucb_buildings\n",
      "Done.\n",
      "100 rows affected.\n",
      "Returning data to local variable result_2b\n"
     ]
    }
   ],
   "source": [
    "%%sql result_2b <<\n",
    "CREATE OR REPLACE VIEW cleaned_data AS\n",
    "SELECT *, \n",
    "    CASE\n",
    "        WHEN outlier = False THEN value\n",
    "        WHEN mad = 0 THEN value\n",
    "        WHEN outlier = True AND value < median - 3 * mad * 1.4826 THEN median - 3 * mad * 1.4826\n",
    "        WHEN outlier = True AND value > median + 3 * mad * 1.4826 THEN median + 3 * mad * 1.4826\n",
    "        END\n",
    "FROM labeled_data\n",
    ";\n",
    "SELECT * FROM cleaned_data WHERE outlier ORDER BY id, time LIMIT 100;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell\n",
    "result_2b.DataFrame().to_csv('results/result_2b.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2b</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q2b results: All test cases passed!"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Question 3: Entity Resolution\n",
    "\n",
    "### Question 3a\n",
    "There is a lot of mess in this dataset related to entity names. As a start, have a look at all of the distinct values in the `units` field of the `metadata` table. What do you notice about these values? Are there any duplicates?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3a\n",
    "manual: true\n",
    "points: 0\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the distinct values refer to the same unit like 'Gal', 'Gallons' and 'Lbs' and 'lbs.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 3b\n",
    "\n",
    "Sometimes, entity resolution is as simple as a text transformation. For example, how many unique `units` values are there, and how many would there be if we ignored case (upper vs. lower case)? Your output should be a table with one row and two columns; the first column should contain the number of unique `units` values, and the second column should contain the number of unique `units` values if we ignored case. The two columns can have arbitrary names.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3bm\n",
    "manual: true\n",
    "points: 0\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   postgresql://jovyan@127.0.0.1:5432/template1\n",
      " * postgresql://jovyan@127.0.0.1:5432/ucb_buildings\n",
      "1 rows affected.\n",
      "Returning data to local variable result_3b\n"
     ]
    }
   ],
   "source": [
    "%%sql result_3b <<\n",
    "SELECT COUNT(DISTINCT units), COUNT(DISTINCT LOWER(units))\n",
    "FROM metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3b\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell\n",
    "result_3b.DataFrame().to_csv('results/result_3b.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3b</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q3b results: All test cases passed!"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 3c\n",
    "\n",
    "Arguably we shouldn't care about these alternative unit labels, *as long as each sensor class uses a single value of `units` for all its sensor ids*. After all, maybe the capitalization means something to somebody!\n",
    "\n",
    "Write a SQL query that returns single row with one column of value `true` if the condition in italics above holds, or a single row with one column of value `false` otherwise. Please do not hard code this query - we reserve the right to penalize your score if you do so.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3cm\n",
    "manual: true\n",
    "points: 0\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   postgresql://jovyan@127.0.0.1:5432/template1\n",
      " * postgresql://jovyan@127.0.0.1:5432/ucb_buildings\n",
      "9509 rows affected.\n",
      "Returning data to local variable result_3c\n"
     ]
    }
   ],
   "source": [
    "%%sql result_3c <<\n",
    "SELECT \n",
    "    CASE\n",
    "        WHEN COUNT(units) = 1 THEN True\n",
    "        ELSE False END\n",
    "        AS one_unit\n",
    "FROM metadata\n",
    "GROUP BY id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3c\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell\n",
    "result_3c.DataFrame().to_csv('results/result_3c.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3c</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q3c results: All test cases passed!"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 3d\n",
    "\n",
    "Moving on, have a look at the `real_estate_metadata` table---starting with the distinct values in the `location` field! What do you notice about these values?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3d\n",
    "manual: true\n",
    "points: 0\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of them are messed up like 'SAN DSAIENG O' and 'FRANCISC SOAN' and I'm assuming 'FRANCISC O,' 'FRANCISC SOAN,' and 'FRANCISC OSAN' all refer to San Francisco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "### Question 3e\n",
    "\n",
    "It turns out this table was the result of an [OCR scan](https://en.wikipedia.org/wiki/Optical_character_recognition). We'll just clean up the `location` column for now, and leave you to imagine the effort to do a full cleanup of all columns.\n",
    "\n",
    "To provide some useful utility functions, we have preloaded Postgres' extension packages for \"fuzzy\" string matching and trigrams for you. You can use any of the string functions in those packages if you like ([as documented here for fuzzystrmatch](https://www.postgresql.org/docs/current/fuzzystrmatch.html) or [here for pg_trgm](https://www.postgresql.org/docs/current/pgtrgm.html)).\n",
    "\n",
    "We also created a lookup table of canonical names, `uc_locations`.\n",
    "\n",
    "Now, using any of the string functions you like (or none at all!), write a SQL query that returns the columns `(building_name, address, location, clean_location)` where `clean_location` contains the best match from `uc_locations.loc_name`. You may find that you can't clean up everything with the string functions, so your view may have to include some specific logic for cases in the data that have to be handled \"manually\". You can choose to do this question in whatever manner you wish as long as your query does not use `CREATE TABLE`, `INSERT INTO`, or `UPDATE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   postgresql://jovyan@127.0.0.1:5432/template1\n",
      " * postgresql://jovyan@127.0.0.1:5432/ucb_buildings\n",
      "5276 rows affected.\n",
      "Returning data to local variable result_3e\n"
     ]
    }
   ],
   "source": [
    "%%sql result_3e <<\n",
    "SELECT building_name, address, location, \n",
    "    CASE\n",
    "    WHEN location = ANY(SELECT loc_name FROM uc_locations) THEN location\n",
    "    WHEN similarity(loc_name, location) > 0.2 THEN loc_name\n",
    "    WHEN location = 'SYSTEMWI DE' THEN 'SYSTEMWIDE'\n",
    "    WHEN location = 'FRANCISC O' THEN 'SAN FRANCISCO'\n",
    "    WHEN location = 'SAN DSAIENG O' THEN 'SAN DIEGO'\n",
    "    WHEN location = 'FRANCISC SOAN' THEN 'SAN FRANCISCO'\n",
    "    WHEN location = 'FRANCISC OSAN' THEN 'SAN FRANCISCO'\n",
    "    END\n",
    "    AS clean_location\n",
    "FROM real_estate_metadata AS r\n",
    "LEFT JOIN uc_locations AS uc\n",
    "ON r.location = uc.loc_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell\n",
    "result_3e.DataFrame().sort_values(['clean_location', 'building_name', 'address']).iloc[::10].to_csv('results/result_3e.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3e</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q3e results: All test cases passed!"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: Interpolating Missing Data\n",
    "Real-world data, real-world problems. Our sensors should be reporting every 15 minutes, but you can be sure that we're missing some data. Here we will fix it. It's a bit more involved than what we looked at in class!\n",
    "\n",
    "### Question 4a: Finding missing readings\n",
    "In the `data` table, the `id` column identifies a unique sensor. Sensor readings should be recorded every 15 minutes from every sensor. Are we missing any readings, and if so which ones? We will focus on readings that are separated by at least 30 minutes or more; readings that are \\[0-30) minutes apart are considered to be fine.\n",
    "\n",
    "To answer this question you'll need to read up a bit on [SQL timestamps](https://www.postgresql.org/docs/current/datatype-datetime.html) and [Functions for manipulating datetime types](https://www.postgresql.org/docs/current/functions-datetime.html). Have a particular look at the following:\n",
    "- The [date_trunc](https://www.postgresql.org/docs/current/functions-datetime.html#FUNCTIONS-DATETIME-TRUNC) function will quantize times to the nearest unit of your choosing. E.g. to round the `time` field to the nearest minute you can say `date_trunc('minute', time)`. **You'll need to quantize to minutes right away before you worry about missing readings.**\n",
    "- There are various ways to enter constant intervals of time as strings. E.g. a 30 minute interval can be written as `interval '30 minutes'` or `'30 minutes'::interval`. See [date/time input](https://www.postgresql.org/docs/current/datatype-datetime.html#DATATYPE-INTERVAL-INPUT) for more info.\n",
    "- You can do arithmetic on date/time types [as documented here](https://www.postgresql.org/docs/current/functions-datetime.html#FUNCTIONS-DATETIME-TRUNC). That will handle all the weird periodicities of clocks and calendars for you. Pay attention to the input and output types of these functions!\n",
    "- Alternatively, the [EXTRACT](https://www.postgresql.org/docs/current/functions-datetime.html#FUNCTIONS-DATETIME-EXTRACT) function is sometimes handy. Note the special `EXTRACT(EPOCH FROM ...)` case. This converts a timestamp into an integer representing the number of seconds since midnight, 1/1/1970 (the dawn of [UNIX time](https://en.wikipedia.org/wiki/Unix_time)!)  You can do normal integer comparisons and arithmetic on the results.\n",
    "- You will need to use the [lag](https://www.geeksforgeeks.org/postgresql-lag-function/) function as the window function.\n",
    "\n",
    "\n",
    "Create a view called `gaps` that augments the `data` schema with three columns:\n",
    "- `lagtime` is the quantized time of the previous reading for that sensor (relative to the current row for a particular row)\n",
    "- `lagvalue` is the value of the previous reading for that sensor\n",
    "- `timediff` is the difference in quantized time between this reading and the previous reading\n",
    "\n",
    "The view should only contain rows where `timediff` is **greater than or equal to 30 minutes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   postgresql://jovyan@127.0.0.1:5432/template1\n",
      " * postgresql://jovyan@127.0.0.1:5432/ucb_buildings\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>time</th>\n",
       "        <th>id</th>\n",
       "        <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2018-06-12 23:00:09+00:00</td>\n",
       "        <td>a3d3326f-20ab-5f1d-97c7-f3084df43f06</td>\n",
       "        <td>65182.74</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(datetime.datetime(2018, 6, 12, 23, 0, 9, tzinfo=datetime.timezone.utc), 'a3d3326f-20ab-5f1d-97c7-f3084df43f06', 65182.74)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT *\n",
    "FROM data\n",
    "LIMIT 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   postgresql://jovyan@127.0.0.1:5432/template1\n",
      " * postgresql://jovyan@127.0.0.1:5432/ucb_buildings\n",
      "Done.\n",
      "Done.\n",
      "10 rows affected.\n",
      "Returning data to local variable result_4a\n"
     ]
    }
   ],
   "source": [
    "%%sql result_4a <<\n",
    "CREATE OR REPLACE VIEW g AS\n",
    "SELECT date_trunc('minute', time) AS time, id, value, LAG(date_trunc('minute', time), 1) OVER (PARTITION BY id ORDER BY time) AS lagtime, LAG(value, 1) OVER (PARTITION BY id ORDER BY time) AS lagvalue, date_trunc('minute', time) - LAG(date_trunc('minute', time), 1) OVER (PARTITION BY id ORDER BY time) AS timediff\n",
    "FROM data;\n",
    "CREATE OR REPLACE VIEW gaps AS\n",
    "SELECT *\n",
    "FROM g\n",
    "WHERE EXTRACT(minute FROM timediff) >= 30\n",
    ";\n",
    "SELECT * FROM gaps ORDER BY id, time LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell\n",
    "result_4a.DataFrame().to_csv('results/result_4a.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q4a</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q4a results: All test cases passed!"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4b: Creating tuples for the missing readings\n",
    "Now we need to manufacture new tuples to fill in the gaps. For example, if you had a tuple from id `abc` timestamped at 1PM today and the next tuple in time from `abc` was timestamped at 1:45PM, you'll need to manufacture two new tuples with id `abc` and `NULL` values: one timestamped at 1:15PM and another timestamped at 1:30PM. We will worry about replacing the `NULL` values in the next step.\n",
    "\n",
    "To manufacture tuples not related to stored data in the database, we'll need to use a *table-valued function* as we did in lecture 12 (when we manufactured data from a normal distribution). The table-valued function we want here is `generate_series` [(documented here)](https://www.postgresql.org/docs/current/functions-srf.html), which we will use to generate *and sequentially timestamp* the right number of tuples to match the number of tuples we found missing.\n",
    "\n",
    "To get a feel for `generate_series`, consider the following simple query that generates a table of integers with intervals of size 3 between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   postgresql://jovyan@127.0.0.1:5432/template1\n",
      " * postgresql://jovyan@127.0.0.1:5432/ucb_buildings\n",
      "4 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>generate_series</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>10</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(1,), (4,), (7,), (10,)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT *\n",
    "  FROM generate_series(1, 10, 3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use `generate_series` in a `LATERAL JOIN` query: for each tuple on the left of the `LATERAL` it will produce a series based on the values of that tuple. So for example, we can generate 2 tuples for each tuple of `uc_locations` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   postgresql://jovyan@127.0.0.1:5432/template1\n",
      " * postgresql://jovyan@127.0.0.1:5432/ucb_buildings\n",
      "24 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>loc_id</th>\n",
       "        <th>loc_name</th>\n",
       "        <th>length</th>\n",
       "        <th>newval</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1</td>\n",
       "        <td>AG FIELD STAT</td>\n",
       "        <td>13</td>\n",
       "        <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1</td>\n",
       "        <td>AG FIELD STAT</td>\n",
       "        <td>13</td>\n",
       "        <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2</td>\n",
       "        <td>BERKELEY</td>\n",
       "        <td>8</td>\n",
       "        <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2</td>\n",
       "        <td>BERKELEY</td>\n",
       "        <td>8</td>\n",
       "        <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>3</td>\n",
       "        <td>DAVIS</td>\n",
       "        <td>5</td>\n",
       "        <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>3</td>\n",
       "        <td>DAVIS</td>\n",
       "        <td>5</td>\n",
       "        <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>4</td>\n",
       "        <td>IRVINE</td>\n",
       "        <td>6</td>\n",
       "        <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>4</td>\n",
       "        <td>IRVINE</td>\n",
       "        <td>6</td>\n",
       "        <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>5</td>\n",
       "        <td>LOS ANGELES</td>\n",
       "        <td>11</td>\n",
       "        <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>5</td>\n",
       "        <td>LOS ANGELES</td>\n",
       "        <td>11</td>\n",
       "        <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>6</td>\n",
       "        <td>MERCED</td>\n",
       "        <td>6</td>\n",
       "        <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>6</td>\n",
       "        <td>MERCED</td>\n",
       "        <td>6</td>\n",
       "        <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>7</td>\n",
       "        <td>RIVERSIDE</td>\n",
       "        <td>9</td>\n",
       "        <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>7</td>\n",
       "        <td>RIVERSIDE</td>\n",
       "        <td>9</td>\n",
       "        <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>8</td>\n",
       "        <td>SAN DIEGO</td>\n",
       "        <td>9</td>\n",
       "        <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>8</td>\n",
       "        <td>SAN DIEGO</td>\n",
       "        <td>9</td>\n",
       "        <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>9</td>\n",
       "        <td>SAN FRANCISCO</td>\n",
       "        <td>13</td>\n",
       "        <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>9</td>\n",
       "        <td>SAN FRANCISCO</td>\n",
       "        <td>13</td>\n",
       "        <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>10</td>\n",
       "        <td>SANTA BARBARA</td>\n",
       "        <td>13</td>\n",
       "        <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>10</td>\n",
       "        <td>SANTA BARBARA</td>\n",
       "        <td>13</td>\n",
       "        <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>11</td>\n",
       "        <td>SANTA CRUZ</td>\n",
       "        <td>10</td>\n",
       "        <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>11</td>\n",
       "        <td>SANTA CRUZ</td>\n",
       "        <td>10</td>\n",
       "        <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>12</td>\n",
       "        <td>SYSTEMWIDE</td>\n",
       "        <td>10</td>\n",
       "        <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>12</td>\n",
       "        <td>SYSTEMWIDE</td>\n",
       "        <td>10</td>\n",
       "        <td>12</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(1, 'AG FIELD STAT', 13, 13),\n",
       " (1, 'AG FIELD STAT', 13, 15),\n",
       " (2, 'BERKELEY', 8, 8),\n",
       " (2, 'BERKELEY', 8, 10),\n",
       " (3, 'DAVIS', 5, 5),\n",
       " (3, 'DAVIS', 5, 7),\n",
       " (4, 'IRVINE', 6, 6),\n",
       " (4, 'IRVINE', 6, 8),\n",
       " (5, 'LOS ANGELES', 11, 11),\n",
       " (5, 'LOS ANGELES', 11, 13),\n",
       " (6, 'MERCED', 6, 6),\n",
       " (6, 'MERCED', 6, 8),\n",
       " (7, 'RIVERSIDE', 9, 9),\n",
       " (7, 'RIVERSIDE', 9, 11),\n",
       " (8, 'SAN DIEGO', 9, 9),\n",
       " (8, 'SAN DIEGO', 9, 11),\n",
       " (9, 'SAN FRANCISCO', 13, 13),\n",
       " (9, 'SAN FRANCISCO', 13, 15),\n",
       " (10, 'SANTA BARBARA', 13, 13),\n",
       " (10, 'SANTA BARBARA', 13, 15),\n",
       " (11, 'SANTA CRUZ', 10, 10),\n",
       " (11, 'SANTA CRUZ', 10, 12),\n",
       " (12, 'SYSTEMWIDE', 10, 10),\n",
       " (12, 'SYSTEMWIDE', 10, 12)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT loc_id, loc_name, length(loc_name), newval\n",
    "  FROM uc_locations u, \n",
    "       LATERAL generate_series(length(loc_name), length(loc_name) + 2, 2) AS newval;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the 2 values it generates are the length of the `loc_name`, and the length + 2. You might want to play with the query above to make sure you understand the documentation for `generate_series` and `LATERAL`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, on to your task!\n",
    "\n",
    "Create a view `complete` that contains the tuples from `data` as well as new tuples that fill in any gaps greater than or equal to 30 minutes. Each gap should be filled by adding tuples in increments of 15 minutes from the *start* of the gap, **with `NULL` as the value**. You probably want to use your `gaps` view as well as `generate_series` to do this!\n",
    "\n",
    "**Hint:** the lower and upper bounds in generate_series (in pseudocode) should be `(lagtime + 15 minutes, time - 15 minutes)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   postgresql://jovyan@127.0.0.1:5432/template1\n",
      " * postgresql://jovyan@127.0.0.1:5432/ucb_buildings\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>time</th>\n",
       "        <th>id</th>\n",
       "        <th>value</th>\n",
       "        <th>lagtime</th>\n",
       "        <th>lagvalue</th>\n",
       "        <th>timediff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2018-06-13 09:15:00+00:00</td>\n",
       "        <td>a3d47b1a-985e-5395-a6ee-719dad9b580f</td>\n",
       "        <td>0.056</td>\n",
       "        <td>2018-06-13 08:45:00+00:00</td>\n",
       "        <td>0.056</td>\n",
       "        <td>0:30:00</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(datetime.datetime(2018, 6, 13, 9, 15, tzinfo=datetime.timezone.utc), 'a3d47b1a-985e-5395-a6ee-719dad9b580f', 0.056, datetime.datetime(2018, 6, 13, 8, 45, tzinfo=datetime.timezone.utc), 0.056, datetime.timedelta(seconds=1800))]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT *\n",
    "FROM gaps\n",
    "LIMIT 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   postgresql://jovyan@127.0.0.1:5432/template1\n",
      " * postgresql://jovyan@127.0.0.1:5432/ucb_buildings\n",
      "3 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>time</th>\n",
       "        <th>id</th>\n",
       "        <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2018-06-12 23:00:09+00:00</td>\n",
       "        <td>a3d3326f-20ab-5f1d-97c7-f3084df43f06</td>\n",
       "        <td>65182.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2018-06-12 22:45:09+00:00</td>\n",
       "        <td>a3d3326f-20ab-5f1d-97c7-f3084df43f06</td>\n",
       "        <td>65182.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2018-06-12 22:30:09+00:00</td>\n",
       "        <td>a3d3326f-20ab-5f1d-97c7-f3084df43f06</td>\n",
       "        <td>65182.27</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(datetime.datetime(2018, 6, 12, 23, 0, 9, tzinfo=datetime.timezone.utc), 'a3d3326f-20ab-5f1d-97c7-f3084df43f06', 65182.74),\n",
       " (datetime.datetime(2018, 6, 12, 22, 45, 9, tzinfo=datetime.timezone.utc), 'a3d3326f-20ab-5f1d-97c7-f3084df43f06', 65182.51),\n",
       " (datetime.datetime(2018, 6, 12, 22, 30, 9, tzinfo=datetime.timezone.utc), 'a3d3326f-20ab-5f1d-97c7-f3084df43f06', 65182.27)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT *\n",
    "FROM data\n",
    "LIMIT 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   postgresql://jovyan@127.0.0.1:5432/template1\n",
      " * postgresql://jovyan@127.0.0.1:5432/ucb_buildings\n",
      "20 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>time</th>\n",
       "        <th>id</th>\n",
       "        <th>value</th>\n",
       "        <th>lagtime</th>\n",
       "        <th>lagvalue</th>\n",
       "        <th>timediff</th>\n",
       "        <th>generate_series</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2018-06-07 00:45:00+00:00</td>\n",
       "        <td>a48e47ab-bbcd-5b39-aaaa-47fbaafe166e</td>\n",
       "        <td>27.273</td>\n",
       "        <td>2018-06-07 00:15:00+00:00</td>\n",
       "        <td>30.0</td>\n",
       "        <td>0:30:00</td>\n",
       "        <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2018-06-07 01:30:00+00:00</td>\n",
       "        <td>a48e47ab-bbcd-5b39-aaaa-47fbaafe166e</td>\n",
       "        <td>27.273</td>\n",
       "        <td>2018-06-07 01:00:00+00:00</td>\n",
       "        <td>23.077</td>\n",
       "        <td>0:30:00</td>\n",
       "        <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2018-06-07 17:45:00+00:00</td>\n",
       "        <td>a48e47ab-bbcd-5b39-aaaa-47fbaafe166e</td>\n",
       "        <td>21.429</td>\n",
       "        <td>2018-06-07 17:15:00+00:00</td>\n",
       "        <td>25.0</td>\n",
       "        <td>0:30:00</td>\n",
       "        <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2018-06-07 18:45:00+00:00</td>\n",
       "        <td>a48e47ab-bbcd-5b39-aaaa-47fbaafe166e</td>\n",
       "        <td>25.0</td>\n",
       "        <td>2018-06-07 18:15:00+00:00</td>\n",
       "        <td>30.0</td>\n",
       "        <td>0:30:00</td>\n",
       "        <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2018-06-07 19:45:00+00:00</td>\n",
       "        <td>a48e47ab-bbcd-5b39-aaaa-47fbaafe166e</td>\n",
       "        <td>23.077</td>\n",
       "        <td>2018-06-07 19:15:00+00:00</td>\n",
       "        <td>20.0</td>\n",
       "        <td>0:30:00</td>\n",
       "        <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2018-06-07 20:30:00+00:00</td>\n",
       "        <td>a48e47ab-bbcd-5b39-aaaa-47fbaafe166e</td>\n",
       "        <td>23.077</td>\n",
       "        <td>2018-06-07 20:00:00+00:00</td>\n",
       "        <td>30.0</td>\n",
       "        <td>0:30:00</td>\n",
       "        <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2018-06-07 21:30:00+00:00</td>\n",
       "        <td>a48e47ab-bbcd-5b39-aaaa-47fbaafe166e</td>\n",
       "        <td>23.077</td>\n",
       "        <td>2018-06-07 21:00:00+00:00</td>\n",
       "        <td>14.286</td>\n",
       "        <td>0:30:00</td>\n",
       "        <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2018-06-07 22:45:00+00:00</td>\n",
       "        <td>a48e47ab-bbcd-5b39-aaaa-47fbaafe166e</td>\n",
       "        <td>21.429</td>\n",
       "        <td>2018-06-07 22:15:00+00:00</td>\n",
       "        <td>30.0</td>\n",
       "        <td>0:30:00</td>\n",
       "        <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2018-06-08 00:30:00+00:00</td>\n",
       "        <td>a48e47ab-bbcd-5b39-aaaa-47fbaafe166e</td>\n",
       "        <td>14.286</td>\n",
       "        <td>2018-06-08 00:00:00+00:00</td>\n",
       "        <td>20.0</td>\n",
       "        <td>0:30:00</td>\n",
       "        <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2018-06-08 01:30:00+00:00</td>\n",
       "        <td>a48e47ab-bbcd-5b39-aaaa-47fbaafe166e</td>\n",
       "        <td>27.273</td>\n",
       "        <td>2018-06-08 01:00:00+00:00</td>\n",
       "        <td>30.0</td>\n",
       "        <td>0:30:00</td>\n",
       "        <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2018-06-08 02:45:00+00:00</td>\n",
       "        <td>a48e47ab-bbcd-5b39-aaaa-47fbaafe166e</td>\n",
       "        <td>27.273</td>\n",
       "        <td>2018-06-08 02:15:00+00:00</td>\n",
       "        <td>20.0</td>\n",
       "        <td>0:30:00</td>\n",
       "        <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2018-06-08 04:30:00+00:00</td>\n",
       "        <td>a48e47ab-bbcd-5b39-aaaa-47fbaafe166e</td>\n",
       "        <td>16.667</td>\n",
       "        <td>2018-06-08 04:00:00+00:00</td>\n",
       "        <td>21.429</td>\n",
       "        <td>0:30:00</td>\n",
       "        <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2018-06-08 05:30:00+00:00</td>\n",
       "        <td>a48e47ab-bbcd-5b39-aaaa-47fbaafe166e</td>\n",
       "        <td>30.0</td>\n",
       "        <td>2018-06-08 05:00:00+00:00</td>\n",
       "        <td>30.0</td>\n",
       "        <td>0:30:00</td>\n",
       "        <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2018-06-08 15:45:00+00:00</td>\n",
       "        <td>a48e47ab-bbcd-5b39-aaaa-47fbaafe166e</td>\n",
       "        <td>27.273</td>\n",
       "        <td>2018-06-08 15:15:00+00:00</td>\n",
       "        <td>25.0</td>\n",
       "        <td>0:30:00</td>\n",
       "        <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2018-06-08 16:30:00+00:00</td>\n",
       "        <td>a48e47ab-bbcd-5b39-aaaa-47fbaafe166e</td>\n",
       "        <td>21.429</td>\n",
       "        <td>2018-06-08 16:00:00+00:00</td>\n",
       "        <td>25.0</td>\n",
       "        <td>0:30:00</td>\n",
       "        <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2018-06-08 17:45:00+00:00</td>\n",
       "        <td>a48e47ab-bbcd-5b39-aaaa-47fbaafe166e</td>\n",
       "        <td>15.0</td>\n",
       "        <td>2018-06-08 17:15:00+00:00</td>\n",
       "        <td>23.077</td>\n",
       "        <td>0:30:00</td>\n",
       "        <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2018-06-08 19:30:00+00:00</td>\n",
       "        <td>a48e47ab-bbcd-5b39-aaaa-47fbaafe166e</td>\n",
       "        <td>30.0</td>\n",
       "        <td>2018-06-08 19:00:00+00:00</td>\n",
       "        <td>23.077</td>\n",
       "        <td>0:30:00</td>\n",
       "        <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2018-06-08 20:30:00+00:00</td>\n",
       "        <td>a48e47ab-bbcd-5b39-aaaa-47fbaafe166e</td>\n",
       "        <td>30.0</td>\n",
       "        <td>2018-06-08 20:00:00+00:00</td>\n",
       "        <td>20.0</td>\n",
       "        <td>0:30:00</td>\n",
       "        <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2018-06-08 21:45:00+00:00</td>\n",
       "        <td>a48e47ab-bbcd-5b39-aaaa-47fbaafe166e</td>\n",
       "        <td>30.0</td>\n",
       "        <td>2018-06-08 21:15:00+00:00</td>\n",
       "        <td>15.789</td>\n",
       "        <td>0:30:00</td>\n",
       "        <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2018-06-08 23:30:00+00:00</td>\n",
       "        <td>a48e47ab-bbcd-5b39-aaaa-47fbaafe166e</td>\n",
       "        <td>27.273</td>\n",
       "        <td>2018-06-08 23:00:00+00:00</td>\n",
       "        <td>16.667</td>\n",
       "        <td>0:30:00</td>\n",
       "        <td>15</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(datetime.datetime(2018, 6, 7, 0, 45, tzinfo=datetime.timezone.utc), 'a48e47ab-bbcd-5b39-aaaa-47fbaafe166e', 27.273, datetime.datetime(2018, 6, 7, 0, 15, tzinfo=datetime.timezone.utc), 30.0, datetime.timedelta(seconds=1800), Decimal('30')),\n",
       " (datetime.datetime(2018, 6, 7, 1, 30, tzinfo=datetime.timezone.utc), 'a48e47ab-bbcd-5b39-aaaa-47fbaafe166e', 27.273, datetime.datetime(2018, 6, 7, 1, 0, tzinfo=datetime.timezone.utc), 23.077, datetime.timedelta(seconds=1800), Decimal('15')),\n",
       " (datetime.datetime(2018, 6, 7, 17, 45, tzinfo=datetime.timezone.utc), 'a48e47ab-bbcd-5b39-aaaa-47fbaafe166e', 21.429, datetime.datetime(2018, 6, 7, 17, 15, tzinfo=datetime.timezone.utc), 25.0, datetime.timedelta(seconds=1800), Decimal('30')),\n",
       " (datetime.datetime(2018, 6, 7, 18, 45, tzinfo=datetime.timezone.utc), 'a48e47ab-bbcd-5b39-aaaa-47fbaafe166e', 25.0, datetime.datetime(2018, 6, 7, 18, 15, tzinfo=datetime.timezone.utc), 30.0, datetime.timedelta(seconds=1800), Decimal('30')),\n",
       " (datetime.datetime(2018, 6, 7, 19, 45, tzinfo=datetime.timezone.utc), 'a48e47ab-bbcd-5b39-aaaa-47fbaafe166e', 23.077, datetime.datetime(2018, 6, 7, 19, 15, tzinfo=datetime.timezone.utc), 20.0, datetime.timedelta(seconds=1800), Decimal('30')),\n",
       " (datetime.datetime(2018, 6, 7, 20, 30, tzinfo=datetime.timezone.utc), 'a48e47ab-bbcd-5b39-aaaa-47fbaafe166e', 23.077, datetime.datetime(2018, 6, 7, 20, 0, tzinfo=datetime.timezone.utc), 30.0, datetime.timedelta(seconds=1800), Decimal('15')),\n",
       " (datetime.datetime(2018, 6, 7, 21, 30, tzinfo=datetime.timezone.utc), 'a48e47ab-bbcd-5b39-aaaa-47fbaafe166e', 23.077, datetime.datetime(2018, 6, 7, 21, 0, tzinfo=datetime.timezone.utc), 14.286, datetime.timedelta(seconds=1800), Decimal('15')),\n",
       " (datetime.datetime(2018, 6, 7, 22, 45, tzinfo=datetime.timezone.utc), 'a48e47ab-bbcd-5b39-aaaa-47fbaafe166e', 21.429, datetime.datetime(2018, 6, 7, 22, 15, tzinfo=datetime.timezone.utc), 30.0, datetime.timedelta(seconds=1800), Decimal('30')),\n",
       " (datetime.datetime(2018, 6, 8, 0, 30, tzinfo=datetime.timezone.utc), 'a48e47ab-bbcd-5b39-aaaa-47fbaafe166e', 14.286, datetime.datetime(2018, 6, 8, 0, 0, tzinfo=datetime.timezone.utc), 20.0, datetime.timedelta(seconds=1800), Decimal('15')),\n",
       " (datetime.datetime(2018, 6, 8, 1, 30, tzinfo=datetime.timezone.utc), 'a48e47ab-bbcd-5b39-aaaa-47fbaafe166e', 27.273, datetime.datetime(2018, 6, 8, 1, 0, tzinfo=datetime.timezone.utc), 30.0, datetime.timedelta(seconds=1800), Decimal('15')),\n",
       " (datetime.datetime(2018, 6, 8, 2, 45, tzinfo=datetime.timezone.utc), 'a48e47ab-bbcd-5b39-aaaa-47fbaafe166e', 27.273, datetime.datetime(2018, 6, 8, 2, 15, tzinfo=datetime.timezone.utc), 20.0, datetime.timedelta(seconds=1800), Decimal('30')),\n",
       " (datetime.datetime(2018, 6, 8, 4, 30, tzinfo=datetime.timezone.utc), 'a48e47ab-bbcd-5b39-aaaa-47fbaafe166e', 16.667, datetime.datetime(2018, 6, 8, 4, 0, tzinfo=datetime.timezone.utc), 21.429, datetime.timedelta(seconds=1800), Decimal('15')),\n",
       " (datetime.datetime(2018, 6, 8, 5, 30, tzinfo=datetime.timezone.utc), 'a48e47ab-bbcd-5b39-aaaa-47fbaafe166e', 30.0, datetime.datetime(2018, 6, 8, 5, 0, tzinfo=datetime.timezone.utc), 30.0, datetime.timedelta(seconds=1800), Decimal('15')),\n",
       " (datetime.datetime(2018, 6, 8, 15, 45, tzinfo=datetime.timezone.utc), 'a48e47ab-bbcd-5b39-aaaa-47fbaafe166e', 27.273, datetime.datetime(2018, 6, 8, 15, 15, tzinfo=datetime.timezone.utc), 25.0, datetime.timedelta(seconds=1800), Decimal('30')),\n",
       " (datetime.datetime(2018, 6, 8, 16, 30, tzinfo=datetime.timezone.utc), 'a48e47ab-bbcd-5b39-aaaa-47fbaafe166e', 21.429, datetime.datetime(2018, 6, 8, 16, 0, tzinfo=datetime.timezone.utc), 25.0, datetime.timedelta(seconds=1800), Decimal('15')),\n",
       " (datetime.datetime(2018, 6, 8, 17, 45, tzinfo=datetime.timezone.utc), 'a48e47ab-bbcd-5b39-aaaa-47fbaafe166e', 15.0, datetime.datetime(2018, 6, 8, 17, 15, tzinfo=datetime.timezone.utc), 23.077, datetime.timedelta(seconds=1800), Decimal('30')),\n",
       " (datetime.datetime(2018, 6, 8, 19, 30, tzinfo=datetime.timezone.utc), 'a48e47ab-bbcd-5b39-aaaa-47fbaafe166e', 30.0, datetime.datetime(2018, 6, 8, 19, 0, tzinfo=datetime.timezone.utc), 23.077, datetime.timedelta(seconds=1800), Decimal('15')),\n",
       " (datetime.datetime(2018, 6, 8, 20, 30, tzinfo=datetime.timezone.utc), 'a48e47ab-bbcd-5b39-aaaa-47fbaafe166e', 30.0, datetime.datetime(2018, 6, 8, 20, 0, tzinfo=datetime.timezone.utc), 20.0, datetime.timedelta(seconds=1800), Decimal('15')),\n",
       " (datetime.datetime(2018, 6, 8, 21, 45, tzinfo=datetime.timezone.utc), 'a48e47ab-bbcd-5b39-aaaa-47fbaafe166e', 30.0, datetime.datetime(2018, 6, 8, 21, 15, tzinfo=datetime.timezone.utc), 15.789, datetime.timedelta(seconds=1800), Decimal('30')),\n",
       " (datetime.datetime(2018, 6, 8, 23, 30, tzinfo=datetime.timezone.utc), 'a48e47ab-bbcd-5b39-aaaa-47fbaafe166e', 27.273, datetime.datetime(2018, 6, 8, 23, 0, tzinfo=datetime.timezone.utc), 16.667, datetime.timedelta(seconds=1800), Decimal('15'))]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT *\n",
    "FROM gaps,\n",
    "    LATERAL generate_series(EXTRACT(minute FROM gaps.lagtime) + 15, EXTRACT(minute FROM time) - 15)\n",
    "LIMIT 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   postgresql://jovyan@127.0.0.1:5432/template1\n",
      " * postgresql://jovyan@127.0.0.1:5432/ucb_buildings\n",
      "Done.\n",
      "100 rows affected.\n",
      "Returning data to local variable result_4b\n"
     ]
    }
   ],
   "source": [
    "%%sql result_4b <<\n",
    "CREATE OR REPLACE VIEW complete AS\n",
    "SELECT data.time, data.id, data.value\n",
    "FROM data, gaps,\n",
    "LATERAL generate_series(EXTRACT(minute FROM gaps.lagtime) + 15, EXTRACT(minute FROM data.time) - 15)\n",
    ";\n",
    "\n",
    "SELECT * FROM complete ORDER BY id, time LIMIT 100;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell\n",
    "result_4b.DataFrame().to_csv('results/result_4b.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong style='color: red;'><pre style='display: inline;'>q4b</pre> results:</strong></p><p><strong><pre style='display: inline;'>q4b - 1</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>q4b - 2</pre> result:</strong></p><pre>    Trying:\n",
       "        pd.read_csv('results/result_4b.csv').iloc[:50]['value'].sum() == 3254484.79\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q4b 1\n",
       "    Failed example:\n",
       "        pd.read_csv('results/result_4b.csv').iloc[:50]['value'].sum() == 3254484.79\n",
       "    Expected:\n",
       "        True\n",
       "    Got:\n",
       "        False\n",
       "</pre>"
      ],
      "text/plain": [
       "q4b results:\n",
       "    q4b - 1 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q4b - 2 result:\n",
       "        Trying:\n",
       "            pd.read_csv('results/result_4b.csv').iloc[:50]['value'].sum() == 3254484.79\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q4b 1\n",
       "        Failed example:\n",
       "            pd.read_csv('results/result_4b.csv').iloc[:50]['value'].sum() == 3254484.79\n",
       "        Expected:\n",
       "            True\n",
       "        Got:\n",
       "            False"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4c: Linear Interpolation\n",
    "*Note: If you struggled with the previous subparts of this problem, you can use our table `complete_provided` instead of your `complete` table in this subpart.*\n",
    "\n",
    "Now, given the `complete` view or the `complete_provided` table, the remaining task is to do linear interpolation to fill in the missing values we manufactured in Step 2. We have code from **this semester's** Lecture 14 (Data Cleaning) we can reuse here! In particular, your database already includes the UDA `coalesce_agg` we used in lecture (you can use it directly, there's no need to redefine it).\n",
    "\n",
    "But note that in Lecture 14's example of linear interpolation we had a field called `entry_rank` that was used to order *all* the records in the table. By contrast, here the ordering we care about is the series of `time` for each sensor `id` *independently*. You will need to make minor changes to adapt the linear interpolation code from class to work here.\n",
    "\n",
    "Create a view `likely_data` that contains all the tuples from `complete`, with an additional column called `interpolated` that contains a copy of `value` if it is non-NULL, otherwise an interpolated value based on linear interpolation *per sensor id over time*. Please **retain all additional columns created from forward and backward passes** (there should be 10 columns in the view - the order of the columns does not matter.) The three cells below correspond to the forward, backward, and final passes from lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   postgresql://jovyan@127.0.0.1:5432/template1\n",
      " * postgresql://jovyan@127.0.0.1:5432/ucb_buildings\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE OR REPLACE VIEW forward AS\n",
    "SELECT *,\n",
    "    SUM(CASE WHEN value IS NULL THEN 0 ELSE 1 END) \n",
    "         OVER (PARTITION BY id ORDER BY time) AS run,\n",
    "       coalesce_agg(value) OVER (PARTITION BY id ORDER BY time) AS run_start,\n",
    "       CASE WHEN value IS NULL \n",
    "              THEN lead(value, 1) OVER (PARTITION BY id ORDER BY time)\n",
    "            ELSE NULL\n",
    "       END AS nextval\n",
    "  FROM complete_provided;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   postgresql://jovyan@127.0.0.1:5432/template1\n",
      " * postgresql://jovyan@127.0.0.1:5432/ucb_buildings\n",
      "10 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>id</th>\n",
       "        <th>time</th>\n",
       "        <th>value</th>\n",
       "        <th>run</th>\n",
       "        <th>run_start</th>\n",
       "        <th>nextval</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>a3d3326f-20ab-5f1d-97c7-f3084df43f06</td>\n",
       "        <td>2018-06-07 00:00:09+00:00</td>\n",
       "        <td>65090.00484684979</td>\n",
       "        <td>1</td>\n",
       "        <td>65090.00484684979</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>a3d3326f-20ab-5f1d-97c7-f3084df43f06</td>\n",
       "        <td>2018-06-07 00:15:09+00:00</td>\n",
       "        <td>65095.063847657846</td>\n",
       "        <td>2</td>\n",
       "        <td>65095.063847657846</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>a3d3326f-20ab-5f1d-97c7-f3084df43f06</td>\n",
       "        <td>2018-06-07 00:30:09+00:00</td>\n",
       "        <td>65088.88889295036</td>\n",
       "        <td>3</td>\n",
       "        <td>65088.88889295036</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>a3d3326f-20ab-5f1d-97c7-f3084df43f06</td>\n",
       "        <td>2018-06-07 00:45:09+00:00</td>\n",
       "        <td>65091.74918576991</td>\n",
       "        <td>4</td>\n",
       "        <td>65091.74918576991</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>a3d3326f-20ab-5f1d-97c7-f3084df43f06</td>\n",
       "        <td>2018-06-07 01:00:09+00:00</td>\n",
       "        <td>65094.52465676664</td>\n",
       "        <td>5</td>\n",
       "        <td>65094.52465676664</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>a3d3326f-20ab-5f1d-97c7-f3084df43f06</td>\n",
       "        <td>2018-06-07 01:15:09+00:00</td>\n",
       "        <td>65091.54352268936</td>\n",
       "        <td>6</td>\n",
       "        <td>65091.54352268936</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>a3d3326f-20ab-5f1d-97c7-f3084df43f06</td>\n",
       "        <td>2018-06-07 01:30:09+00:00</td>\n",
       "        <td>65091.92453754127</td>\n",
       "        <td>7</td>\n",
       "        <td>65091.92453754127</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>a3d3326f-20ab-5f1d-97c7-f3084df43f06</td>\n",
       "        <td>2018-06-07 01:45:09+00:00</td>\n",
       "        <td>65090.50560937036</td>\n",
       "        <td>8</td>\n",
       "        <td>65090.50560937036</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>a3d3326f-20ab-5f1d-97c7-f3084df43f06</td>\n",
       "        <td>2018-06-07 02:00:09+00:00</td>\n",
       "        <td>65095.217779690916</td>\n",
       "        <td>9</td>\n",
       "        <td>65095.217779690916</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>a3d3326f-20ab-5f1d-97c7-f3084df43f06</td>\n",
       "        <td>2018-06-07 02:15:09+00:00</td>\n",
       "        <td>65088.44877438346</td>\n",
       "        <td>10</td>\n",
       "        <td>65088.44877438346</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('a3d3326f-20ab-5f1d-97c7-f3084df43f06', datetime.datetime(2018, 6, 7, 0, 0, 9, tzinfo=datetime.timezone.utc), 65090.00484684979, 1, 65090.00484684979, None),\n",
       " ('a3d3326f-20ab-5f1d-97c7-f3084df43f06', datetime.datetime(2018, 6, 7, 0, 15, 9, tzinfo=datetime.timezone.utc), 65095.063847657846, 2, 65095.063847657846, None),\n",
       " ('a3d3326f-20ab-5f1d-97c7-f3084df43f06', datetime.datetime(2018, 6, 7, 0, 30, 9, tzinfo=datetime.timezone.utc), 65088.88889295036, 3, 65088.88889295036, None),\n",
       " ('a3d3326f-20ab-5f1d-97c7-f3084df43f06', datetime.datetime(2018, 6, 7, 0, 45, 9, tzinfo=datetime.timezone.utc), 65091.74918576991, 4, 65091.74918576991, None),\n",
       " ('a3d3326f-20ab-5f1d-97c7-f3084df43f06', datetime.datetime(2018, 6, 7, 1, 0, 9, tzinfo=datetime.timezone.utc), 65094.52465676664, 5, 65094.52465676664, None),\n",
       " ('a3d3326f-20ab-5f1d-97c7-f3084df43f06', datetime.datetime(2018, 6, 7, 1, 15, 9, tzinfo=datetime.timezone.utc), 65091.54352268936, 6, 65091.54352268936, None),\n",
       " ('a3d3326f-20ab-5f1d-97c7-f3084df43f06', datetime.datetime(2018, 6, 7, 1, 30, 9, tzinfo=datetime.timezone.utc), 65091.92453754127, 7, 65091.92453754127, None),\n",
       " ('a3d3326f-20ab-5f1d-97c7-f3084df43f06', datetime.datetime(2018, 6, 7, 1, 45, 9, tzinfo=datetime.timezone.utc), 65090.50560937036, 8, 65090.50560937036, None),\n",
       " ('a3d3326f-20ab-5f1d-97c7-f3084df43f06', datetime.datetime(2018, 6, 7, 2, 0, 9, tzinfo=datetime.timezone.utc), 65095.217779690916, 9, 65095.217779690916, None),\n",
       " ('a3d3326f-20ab-5f1d-97c7-f3084df43f06', datetime.datetime(2018, 6, 7, 2, 15, 9, tzinfo=datetime.timezone.utc), 65088.44877438346, 10, 65088.44877438346, None)]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT *\n",
    "FROM forward\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   postgresql://jovyan@127.0.0.1:5432/template1\n",
      " * postgresql://jovyan@127.0.0.1:5432/ucb_buildings\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE OR REPLACE VIEW backward AS\n",
    "SELECT *,\n",
    "       CASE WHEN value IS NOT NULL THEN value\n",
    "            ELSE coalesce_agg(nextval) OVER (PARTITION BY id, run ORDER BY time DESC)\n",
    "       END AS run_end,\n",
    "       count(*) OVER (PARTITION BY id, run) AS run_size,\n",
    "       count(*) OVER (PARTITION BY id, run ORDER BY time) AS run_rank\n",
    "  FROM forward;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   postgresql://jovyan@127.0.0.1:5432/template1\n",
      " * postgresql://jovyan@127.0.0.1:5432/ucb_buildings\n",
      "3 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>id</th>\n",
       "        <th>time</th>\n",
       "        <th>value</th>\n",
       "        <th>run</th>\n",
       "        <th>run_start</th>\n",
       "        <th>nextval</th>\n",
       "        <th>run_end</th>\n",
       "        <th>run_size</th>\n",
       "        <th>run_rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>a3d3326f-20ab-5f1d-97c7-f3084df43f06</td>\n",
       "        <td>2018-06-07 00:00:09+00:00</td>\n",
       "        <td>65090.00484684979</td>\n",
       "        <td>1</td>\n",
       "        <td>65090.00484684979</td>\n",
       "        <td>None</td>\n",
       "        <td>65090.00484684979</td>\n",
       "        <td>1</td>\n",
       "        <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>a3d3326f-20ab-5f1d-97c7-f3084df43f06</td>\n",
       "        <td>2018-06-07 00:15:09+00:00</td>\n",
       "        <td>65095.063847657846</td>\n",
       "        <td>2</td>\n",
       "        <td>65095.063847657846</td>\n",
       "        <td>None</td>\n",
       "        <td>65095.063847657846</td>\n",
       "        <td>1</td>\n",
       "        <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>a3d3326f-20ab-5f1d-97c7-f3084df43f06</td>\n",
       "        <td>2018-06-07 00:30:09+00:00</td>\n",
       "        <td>65088.88889295036</td>\n",
       "        <td>3</td>\n",
       "        <td>65088.88889295036</td>\n",
       "        <td>None</td>\n",
       "        <td>65088.88889295036</td>\n",
       "        <td>1</td>\n",
       "        <td>1</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('a3d3326f-20ab-5f1d-97c7-f3084df43f06', datetime.datetime(2018, 6, 7, 0, 0, 9, tzinfo=datetime.timezone.utc), 65090.00484684979, 1, 65090.00484684979, None, 65090.00484684979, 1, 1),\n",
       " ('a3d3326f-20ab-5f1d-97c7-f3084df43f06', datetime.datetime(2018, 6, 7, 0, 15, 9, tzinfo=datetime.timezone.utc), 65095.063847657846, 2, 65095.063847657846, None, 65095.063847657846, 1, 1),\n",
       " ('a3d3326f-20ab-5f1d-97c7-f3084df43f06', datetime.datetime(2018, 6, 7, 0, 30, 9, tzinfo=datetime.timezone.utc), 65088.88889295036, 3, 65088.88889295036, None, 65088.88889295036, 1, 1)]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT *\n",
    "FROM backward\n",
    "LIMIT 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   postgresql://jovyan@127.0.0.1:5432/template1\n",
      " * postgresql://jovyan@127.0.0.1:5432/ucb_buildings\n",
      "Done.\n",
      "(psycopg2.ProgrammingError) can't execute an empty query\n",
      "[SQL: ;]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n"
     ]
    }
   ],
   "source": [
    "%%sql result_4c <<\n",
    "CREATE OR REPLACE VIEW likely_data AS\n",
    "SELECT *, \n",
    "       run_start + (run_rank-1)*((run_end-run_start)/(run_size))\n",
    "         AS interpolated\n",
    "  FROM backward;\n",
    ";\n",
    "SELECT * FROM likely_data WHERE run_size > 2 ORDER BY id, time LIMIT 100;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   postgresql://jovyan@127.0.0.1:5432/template1\n",
      " * postgresql://jovyan@127.0.0.1:5432/ucb_buildings\n",
      "3 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>id</th>\n",
       "        <th>time</th>\n",
       "        <th>value</th>\n",
       "        <th>run</th>\n",
       "        <th>run_start</th>\n",
       "        <th>nextval</th>\n",
       "        <th>run_end</th>\n",
       "        <th>run_size</th>\n",
       "        <th>run_rank</th>\n",
       "        <th>interpolated</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>a3d3326f-20ab-5f1d-97c7-f3084df43f06</td>\n",
       "        <td>2018-06-07 00:00:09+00:00</td>\n",
       "        <td>65090.00484684979</td>\n",
       "        <td>1</td>\n",
       "        <td>65090.00484684979</td>\n",
       "        <td>None</td>\n",
       "        <td>65090.00484684979</td>\n",
       "        <td>573</td>\n",
       "        <td>1</td>\n",
       "        <td>65090.00484684979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>a3d3326f-20ab-5f1d-97c7-f3084df43f06</td>\n",
       "        <td>2018-06-07 00:15:09+00:00</td>\n",
       "        <td>65095.063847657846</td>\n",
       "        <td>2</td>\n",
       "        <td>65095.063847657846</td>\n",
       "        <td>None</td>\n",
       "        <td>65095.063847657846</td>\n",
       "        <td>573</td>\n",
       "        <td>2</td>\n",
       "        <td>65095.063847657846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>a3d3326f-20ab-5f1d-97c7-f3084df43f06</td>\n",
       "        <td>2018-06-07 00:30:09+00:00</td>\n",
       "        <td>65088.88889295036</td>\n",
       "        <td>3</td>\n",
       "        <td>65088.88889295036</td>\n",
       "        <td>None</td>\n",
       "        <td>65088.88889295036</td>\n",
       "        <td>573</td>\n",
       "        <td>3</td>\n",
       "        <td>65088.88889295036</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('a3d3326f-20ab-5f1d-97c7-f3084df43f06', datetime.datetime(2018, 6, 7, 0, 0, 9, tzinfo=datetime.timezone.utc), 65090.00484684979, 1, 65090.00484684979, None, 65090.00484684979, 573, 1, 65090.00484684979),\n",
       " ('a3d3326f-20ab-5f1d-97c7-f3084df43f06', datetime.datetime(2018, 6, 7, 0, 15, 9, tzinfo=datetime.timezone.utc), 65095.063847657846, 2, 65095.063847657846, None, 65095.063847657846, 573, 2, 65095.063847657846),\n",
       " ('a3d3326f-20ab-5f1d-97c7-f3084df43f06', datetime.datetime(2018, 6, 7, 0, 30, 9, tzinfo=datetime.timezone.utc), 65088.88889295036, 3, 65088.88889295036, None, 65088.88889295036, 573, 3, 65088.88889295036)]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT *\n",
    "FROM likely_data\n",
    "LIMIT 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result_4c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [188], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Do not delete/edit this cell\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m result_4c\u001b[38;5;241m.\u001b[39mDataFrame()\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults/result_4c.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result_4c' is not defined"
     ]
    }
   ],
   "source": [
    "# Do not delete/edit this cell\n",
    "result_4c.DataFrame().to_csv('results/result_4c.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong style='color: red;'><pre style='display: inline;'>q4c</pre> results:</strong></p><p><strong><pre style='display: inline;'>q4c - 1</pre> result:</strong></p><pre>    Trying:\n",
       "        pd.read_csv('results/result_4c.csv').shape == (100, 10)\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q4c 0\n",
       "    Failed example:\n",
       "        pd.read_csv('results/result_4c.csv').shape == (100, 10)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/opt/conda/lib/python3.9/doctest.py\", line 1334, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q4c 0[0]>\", line 1, in <module>\n",
       "            pd.read_csv('results/result_4c.csv').shape == (100, 10)\n",
       "          File \"/opt/conda/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
       "            return func(*args, **kwargs)\n",
       "          File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n",
       "            return _read(filepath_or_buffer, kwds)\n",
       "          File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n",
       "            parser = TextFileReader(filepath_or_buffer, **kwds)\n",
       "          File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n",
       "            self._engine = self._make_engine(self.engine)\n",
       "          File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n",
       "            return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n",
       "          File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n",
       "            self._open_handles(src, kwds)\n",
       "          File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\n",
       "            self.handles = get_handle(\n",
       "          File \"/opt/conda/lib/python3.9/site-packages/pandas/io/common.py\", line 702, in get_handle\n",
       "            handle = open(\n",
       "        FileNotFoundError: [Errno 2] No such file or directory: 'results/result_4c.csv'\n",
       "</pre><p><strong><pre style='display: inline;'>q4c - 2</pre> result:</strong></p><pre>    Trying:\n",
       "        np.isclose(pd.read_csv('results/result_4c.csv').iloc[:50]['interpolated'].sum(), 195.94525) or np.isclose(pd.read_csv('results/result_4c.csv').iloc[:50]['interpolated'].sum(), 369.7514880904479)\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q4c 1\n",
       "    Failed example:\n",
       "        np.isclose(pd.read_csv('results/result_4c.csv').iloc[:50]['interpolated'].sum(), 195.94525) or np.isclose(pd.read_csv('results/result_4c.csv').iloc[:50]['interpolated'].sum(), 369.7514880904479)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/opt/conda/lib/python3.9/doctest.py\", line 1334, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q4c 1[0]>\", line 1, in <module>\n",
       "            np.isclose(pd.read_csv('results/result_4c.csv').iloc[:50]['interpolated'].sum(), 195.94525) or np.isclose(pd.read_csv('results/result_4c.csv').iloc[:50]['interpolated'].sum(), 369.7514880904479)\n",
       "          File \"/opt/conda/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
       "            return func(*args, **kwargs)\n",
       "          File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n",
       "            return _read(filepath_or_buffer, kwds)\n",
       "          File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n",
       "            parser = TextFileReader(filepath_or_buffer, **kwds)\n",
       "          File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n",
       "            self._engine = self._make_engine(self.engine)\n",
       "          File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n",
       "            return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n",
       "          File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n",
       "            self._open_handles(src, kwds)\n",
       "          File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\n",
       "            self.handles = get_handle(\n",
       "          File \"/opt/conda/lib/python3.9/site-packages/pandas/io/common.py\", line 702, in get_handle\n",
       "            handle = open(\n",
       "        FileNotFoundError: [Errno 2] No such file or directory: 'results/result_4c.csv'\n",
       "</pre>"
      ],
      "text/plain": [
       "q4c results:\n",
       "    q4c - 1 result:\n",
       "        Trying:\n",
       "            pd.read_csv('results/result_4c.csv').shape == (100, 10)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q4c 0\n",
       "        Failed example:\n",
       "            pd.read_csv('results/result_4c.csv').shape == (100, 10)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/conda/lib/python3.9/doctest.py\", line 1334, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q4c 0[0]>\", line 1, in <module>\n",
       "                pd.read_csv('results/result_4c.csv').shape == (100, 10)\n",
       "              File \"/opt/conda/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
       "                return func(*args, **kwargs)\n",
       "              File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n",
       "                return _read(filepath_or_buffer, kwds)\n",
       "              File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n",
       "                parser = TextFileReader(filepath_or_buffer, **kwds)\n",
       "              File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n",
       "                self._engine = self._make_engine(self.engine)\n",
       "              File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n",
       "                return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n",
       "              File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n",
       "                self._open_handles(src, kwds)\n",
       "              File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\n",
       "                self.handles = get_handle(\n",
       "              File \"/opt/conda/lib/python3.9/site-packages/pandas/io/common.py\", line 702, in get_handle\n",
       "                handle = open(\n",
       "            FileNotFoundError: [Errno 2] No such file or directory: 'results/result_4c.csv'\n",
       "\n",
       "    q4c - 2 result:\n",
       "        Trying:\n",
       "            np.isclose(pd.read_csv('results/result_4c.csv').iloc[:50]['interpolated'].sum(), 195.94525) or np.isclose(pd.read_csv('results/result_4c.csv').iloc[:50]['interpolated'].sum(), 369.7514880904479)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q4c 1\n",
       "        Failed example:\n",
       "            np.isclose(pd.read_csv('results/result_4c.csv').iloc[:50]['interpolated'].sum(), 195.94525) or np.isclose(pd.read_csv('results/result_4c.csv').iloc[:50]['interpolated'].sum(), 369.7514880904479)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/conda/lib/python3.9/doctest.py\", line 1334, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q4c 1[0]>\", line 1, in <module>\n",
       "                np.isclose(pd.read_csv('results/result_4c.csv').iloc[:50]['interpolated'].sum(), 195.94525) or np.isclose(pd.read_csv('results/result_4c.csv').iloc[:50]['interpolated'].sum(), 369.7514880904479)\n",
       "              File \"/opt/conda/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
       "                return func(*args, **kwargs)\n",
       "              File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n",
       "                return _read(filepath_or_buffer, kwds)\n",
       "              File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n",
       "                parser = TextFileReader(filepath_or_buffer, **kwds)\n",
       "              File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n",
       "                self._engine = self._make_engine(self.engine)\n",
       "              File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n",
       "                return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n",
       "              File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n",
       "                self._open_handles(src, kwds)\n",
       "              File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\n",
       "                self.handles = get_handle(\n",
       "              File \"/opt/conda/lib/python3.9/site-packages/pandas/io/common.py\", line 702, in get_handle\n",
       "                handle = open(\n",
       "            FileNotFoundError: [Errno 2] No such file or directory: 'results/result_4c.csv'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You have finished Project 3.\n",
    "\n",
    "Run the following cell to zip and download the results of your queries. You will also need to run the export cell at the end of the notebook.\n",
    "\n",
    "**For submission on Gradescope, you will need to submit BOTH the proj3.zip file genreated by the export cell and the results.zip file generated by the following cell.**\n",
    "\n",
    "**Common submission issues:** You MUST submit the generated zip files (not folders) to the autograder. However, Safari is known to automatically unzip files upon downloading. You can fix this by going into Safari preferences, and deselect the box with the text \"Open safe files after downloading\" under the \"General\" tab. If you experience issues with downloading via clicking on the link, you can also navigate to the project 3 directory within JupyterHub (remove `proj3.ipynb` from the url), and manually download the generated zip files. Please post on Ed if you encounter any other submission issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: results/ (stored 0%)\r\n",
      "  adding: results/result_1b.csv (deflated 78%)\r\n",
      "  adding: results/result_1c.csv (deflated 57%)\r\n",
      "  adding: results/result_2a.csv (deflated 92%)\r\n",
      "  adding: results/result_2b.csv (deflated 92%)\r\n",
      "  adding: results/result_3b.csv (deflated 6%)\r\n",
      "  adding: results/result_3c.csv (deflated 100%)\r\n",
      "  adding: results/result_3e.csv (deflated 76%)\r\n",
      "  adding: results/result_4a.csv (deflated 73%)\r\n",
      "  adding: results/result_4b.csv (deflated 98%)\r\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Click here to download: <a href='./results.zip' target='_blank'>./results.zip</a><br>"
      ],
      "text/plain": [
       "/home/jovyan/fa22/proj/proj3/results.zip"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, FileLink\n",
    "\n",
    "!zip -r results.zip results\n",
    "results_file = FileLink('./results.zip', result_html_prefix=\"Click here to download: \")\n",
    "display(results_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q1b results: All test cases passed!\n",
       "\n",
       "q1c results: All test cases passed!\n",
       "\n",
       "q2a results: All test cases passed!\n",
       "\n",
       "q2b results: All test cases passed!\n",
       "\n",
       "q3b results: All test cases passed!\n",
       "\n",
       "q3c results: All test cases passed!\n",
       "\n",
       "q3e results: All test cases passed!\n",
       "\n",
       "q4a results: All test cases passed!\n",
       "\n",
       "q4b results:\n",
       "    q4b - 1 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q4b - 2 result:\n",
       "        Trying:\n",
       "            pd.read_csv('results/result_4b.csv').iloc[:50]['value'].sum() == 3254484.79\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q4b 1\n",
       "        Failed example:\n",
       "            pd.read_csv('results/result_4b.csv').iloc[:50]['value'].sum() == 3254484.79\n",
       "        Expected:\n",
       "            True\n",
       "        Got:\n",
       "            False\n",
       "\n",
       "q4c results:\n",
       "    q4c - 1 result:\n",
       "        Trying:\n",
       "            pd.read_csv('results/result_4c.csv').shape == (100, 10)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q4c 0\n",
       "        Failed example:\n",
       "            pd.read_csv('results/result_4c.csv').shape == (100, 10)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/conda/lib/python3.9/doctest.py\", line 1334, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q4c 0[0]>\", line 1, in <module>\n",
       "                pd.read_csv('results/result_4c.csv').shape == (100, 10)\n",
       "              File \"/opt/conda/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
       "                return func(*args, **kwargs)\n",
       "              File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n",
       "                return _read(filepath_or_buffer, kwds)\n",
       "              File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n",
       "                parser = TextFileReader(filepath_or_buffer, **kwds)\n",
       "              File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n",
       "                self._engine = self._make_engine(self.engine)\n",
       "              File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n",
       "                return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n",
       "              File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n",
       "                self._open_handles(src, kwds)\n",
       "              File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\n",
       "                self.handles = get_handle(\n",
       "              File \"/opt/conda/lib/python3.9/site-packages/pandas/io/common.py\", line 702, in get_handle\n",
       "                handle = open(\n",
       "            FileNotFoundError: [Errno 2] No such file or directory: 'results/result_4c.csv'\n",
       "\n",
       "    q4c - 2 result:\n",
       "        Trying:\n",
       "            np.isclose(pd.read_csv('results/result_4c.csv').iloc[:50]['interpolated'].sum(), 195.94525) or np.isclose(pd.read_csv('results/result_4c.csv').iloc[:50]['interpolated'].sum(), 369.7514880904479)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q4c 1\n",
       "        Failed example:\n",
       "            np.isclose(pd.read_csv('results/result_4c.csv').iloc[:50]['interpolated'].sum(), 195.94525) or np.isclose(pd.read_csv('results/result_4c.csv').iloc[:50]['interpolated'].sum(), 369.7514880904479)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/conda/lib/python3.9/doctest.py\", line 1334, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q4c 1[0]>\", line 1, in <module>\n",
       "                np.isclose(pd.read_csv('results/result_4c.csv').iloc[:50]['interpolated'].sum(), 195.94525) or np.isclose(pd.read_csv('results/result_4c.csv').iloc[:50]['interpolated'].sum(), 369.7514880904479)\n",
       "              File \"/opt/conda/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
       "                return func(*args, **kwargs)\n",
       "              File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n",
       "                return _read(filepath_or_buffer, kwds)\n",
       "              File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n",
       "                parser = TextFileReader(filepath_or_buffer, **kwds)\n",
       "              File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n",
       "                self._engine = self._make_engine(self.engine)\n",
       "              File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n",
       "                return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n",
       "              File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n",
       "                self._open_handles(src, kwds)\n",
       "              File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\n",
       "                self.handles = get_handle(\n",
       "              File \"/opt/conda/lib/python3.9/site-packages/pandas/io/common.py\", line 702, in get_handle\n",
       "                handle = open(\n",
       "            FileNotFoundError: [Errno 2] No such file or directory: 'results/result_4c.csv'"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
